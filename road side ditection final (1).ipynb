{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense,Dropout,Flatten\n",
    "from keras.optimizers import adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'C:/final model/classification train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = []\n",
    "for i in range(59):\n",
    "    CATEGORIES.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE = 50\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES: \n",
    "\n",
    "        path = os.path.join(DATADIR,category)  \n",
    "        class_num = CATEGORIES.index(category)  \n",
    "        #print('hello')\n",
    "        for img in tqdm(os.listdir(path)):  \n",
    "            try:\n",
    "                #print(path)\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
    "                #print(img_array)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "                #print(new_array)\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:  \n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 88.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 332.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 321.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 418.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 208/208 [00:00<00:00, 461.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 308.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 463.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 235/235 [00:00<00:00, 465.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 659.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 199.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 168.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 630/630 [00:01<00:00, 603.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 195/195 [00:00<00:00, 553.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 494.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 494.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 404.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 412.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 311.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 545.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:00<00:00, 491.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 364.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 534.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 616.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [00:00<00:00, 553.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 318.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [00:00<00:00, 673.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 588.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 326/326 [00:00<00:00, 703.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 500.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 703.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 589.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 531.18it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 565.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 438.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 180/180 [00:00<00:00, 609.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 553.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 513.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 210/210 [00:00<00:00, 493.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 564.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 623.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 708.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 453.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 315/315 [00:00<00:00, 485.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 425.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 430.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 465/465 [00:00<00:00, 527.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 656.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 431.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 265.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 450/450 [00:00<00:00, 608.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 347.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 169.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 267.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 527.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 279.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 460.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 471.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 572.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 556.18it/s]\n"
     ]
    }
   ],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CG-DTE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(59, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CG-DTE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5231 samples, validate on 2243 samples\n",
      "Epoch 1/3\n",
      "5231/5231 [==============================] - ETA: 30:44 - loss: 4.0973 - acc: 0.0000e+ - ETA: 21:57 - loss: 4.3676 - acc: 0.0000e+ - ETA: 19:01 - loss: 4.2099 - acc: 0.0312   - ETA: 17:38 - loss: 4.1309 - acc: 0.03 - ETA: 16:36 - loss: 4.0835 - acc: 0.05 - ETA: 15:57 - loss: 4.0724 - acc: 0.05 - ETA: 15:31 - loss: 4.0471 - acc: 0.06 - ETA: 15:04 - loss: 4.0112 - acc: 0.07 - ETA: 14:43 - loss: 3.9824 - acc: 0.08 - ETA: 14:41 - loss: 3.9641 - acc: 0.09 - ETA: 14:25 - loss: 3.9617 - acc: 0.08 - ETA: 14:11 - loss: 3.9505 - acc: 0.08 - ETA: 14:01 - loss: 3.9331 - acc: 0.08 - ETA: 13:47 - loss: 3.9246 - acc: 0.08 - ETA: 13:36 - loss: 3.9166 - acc: 0.07 - ETA: 13:28 - loss: 3.9041 - acc: 0.08 - ETA: 13:18 - loss: 3.8998 - acc: 0.08 - ETA: 13:09 - loss: 3.8912 - acc: 0.09 - ETA: 13:02 - loss: 3.8853 - acc: 0.09 - ETA: 12:53 - loss: 3.8830 - acc: 0.09 - ETA: 12:44 - loss: 3.8751 - acc: 0.09 - ETA: 12:38 - loss: 3.8601 - acc: 0.09 - ETA: 12:30 - loss: 3.8479 - acc: 0.09 - ETA: 12:22 - loss: 3.8268 - acc: 0.10 - ETA: 12:16 - loss: 3.8134 - acc: 0.10 - ETA: 12:09 - loss: 3.8116 - acc: 0.10 - ETA: 12:02 - loss: 3.7946 - acc: 0.10 - ETA: 11:56 - loss: 3.7878 - acc: 0.10 - ETA: 11:49 - loss: 3.7837 - acc: 0.10 - ETA: 11:42 - loss: 3.7799 - acc: 0.10 - ETA: 11:36 - loss: 3.7802 - acc: 0.10 - ETA: 11:30 - loss: 3.7743 - acc: 0.10 - ETA: 11:23 - loss: 3.7694 - acc: 0.10 - ETA: 11:17 - loss: 3.7640 - acc: 0.10 - ETA: 11:15 - loss: 3.7525 - acc: 0.11 - ETA: 11:11 - loss: 3.7426 - acc: 0.12 - ETA: 11:05 - loss: 3.7396 - acc: 0.12 - ETA: 10:59 - loss: 3.7310 - acc: 0.12 - ETA: 10:53 - loss: 3.7265 - acc: 0.12 - ETA: 10:48 - loss: 3.7158 - acc: 0.12 - ETA: 10:41 - loss: 3.7114 - acc: 0.12 - ETA: 10:35 - loss: 3.7021 - acc: 0.12 - ETA: 10:30 - loss: 3.7001 - acc: 0.12 - ETA: 10:25 - loss: 3.6930 - acc: 0.12 - ETA: 10:19 - loss: 3.6828 - acc: 0.12 - ETA: 10:14 - loss: 3.6731 - acc: 0.12 - ETA: 10:08 - loss: 3.6630 - acc: 0.12 - ETA: 10:03 - loss: 3.6609 - acc: 0.12 - ETA: 9:58 - loss: 3.6564 - acc: 0.1288 - ETA: 9:53 - loss: 3.6457 - acc: 0.133 - ETA: 9:48 - loss: 3.6329 - acc: 0.136 - ETA: 9:43 - loss: 3.6280 - acc: 0.140 - ETA: 9:38 - loss: 3.6189 - acc: 0.145 - ETA: 9:32 - loss: 3.6104 - acc: 0.150 - ETA: 9:27 - loss: 3.5985 - acc: 0.155 - ETA: 9:22 - loss: 3.5933 - acc: 0.156 - ETA: 9:16 - loss: 3.5836 - acc: 0.160 - ETA: 9:11 - loss: 3.5696 - acc: 0.164 - ETA: 9:05 - loss: 3.5546 - acc: 0.167 - ETA: 8:59 - loss: 3.5422 - acc: 0.171 - ETA: 8:54 - loss: 3.5339 - acc: 0.174 - ETA: 8:49 - loss: 3.5226 - acc: 0.177 - ETA: 8:43 - loss: 3.5110 - acc: 0.181 - ETA: 8:38 - loss: 3.5055 - acc: 0.182 - ETA: 8:32 - loss: 3.4885 - acc: 0.186 - ETA: 8:27 - loss: 3.4714 - acc: 0.191 - ETA: 8:22 - loss: 3.4571 - acc: 0.195 - ETA: 8:16 - loss: 3.4521 - acc: 0.196 - ETA: 8:11 - loss: 3.4373 - acc: 0.200 - ETA: 8:06 - loss: 3.4287 - acc: 0.202 - ETA: 8:00 - loss: 3.4242 - acc: 0.203 - ETA: 7:55 - loss: 3.4100 - acc: 0.208 - ETA: 7:49 - loss: 3.3980 - acc: 0.211 - ETA: 7:44 - loss: 3.3826 - acc: 0.212 - ETA: 7:39 - loss: 3.3726 - acc: 0.215 - ETA: 7:33 - loss: 3.3671 - acc: 0.217 - ETA: 7:28 - loss: 3.3608 - acc: 0.219 - ETA: 7:22 - loss: 3.3475 - acc: 0.221 - ETA: 7:17 - loss: 3.3317 - acc: 0.225 - ETA: 7:12 - loss: 3.3193 - acc: 0.228 - ETA: 7:08 - loss: 3.2994 - acc: 0.232 - ETA: 7:03 - loss: 3.2860 - acc: 0.234 - ETA: 6:58 - loss: 3.2694 - acc: 0.237 - ETA: 6:53 - loss: 3.2559 - acc: 0.239 - ETA: 6:48 - loss: 3.2451 - acc: 0.241 - ETA: 6:42 - loss: 3.2303 - acc: 0.244 - ETA: 6:37 - loss: 3.2119 - acc: 0.249 - ETA: 6:32 - loss: 3.2041 - acc: 0.251 - ETA: 6:27 - loss: 3.1871 - acc: 0.254 - ETA: 6:21 - loss: 3.1712 - acc: 0.258 - ETA: 6:16 - loss: 3.1539 - acc: 0.262 - ETA: 6:11 - loss: 3.1445 - acc: 0.263 - ETA: 6:05 - loss: 3.1303 - acc: 0.267 - ETA: 6:00 - loss: 3.1171 - acc: 0.270 - ETA: 5:55 - loss: 3.0998 - acc: 0.274 - ETA: 5:49 - loss: 3.0838 - acc: 0.277 - ETA: 5:44 - loss: 3.0732 - acc: 0.280 - ETA: 5:39 - loss: 3.0622 - acc: 0.281 - ETA: 5:34 - loss: 3.0480 - acc: 0.285 - ETA: 5:28 - loss: 3.0323 - acc: 0.288 - ETA: 5:23 - loss: 3.0183 - acc: 0.292 - ETA: 5:18 - loss: 3.0094 - acc: 0.294 - ETA: 5:12 - loss: 2.9987 - acc: 0.297 - ETA: 5:07 - loss: 2.9834 - acc: 0.300 - ETA: 5:02 - loss: 2.9722 - acc: 0.303 - ETA: 4:57 - loss: 2.9610 - acc: 0.305 - ETA: 4:51 - loss: 2.9470 - acc: 0.308 - ETA: 4:46 - loss: 2.9338 - acc: 0.311 - ETA: 4:41 - loss: 2.9209 - acc: 0.313 - ETA: 4:36 - loss: 2.9111 - acc: 0.315 - ETA: 4:30 - loss: 2.8984 - acc: 0.318 - ETA: 4:25 - loss: 2.8881 - acc: 0.320 - ETA: 4:20 - loss: 2.8766 - acc: 0.323 - ETA: 4:15 - loss: 2.8704 - acc: 0.324 - ETA: 4:10 - loss: 2.8555 - acc: 0.327 - ETA: 4:04 - loss: 2.8443 - acc: 0.329 - ETA: 3:59 - loss: 2.8288 - acc: 0.332 - ETA: 3:54 - loss: 2.8193 - acc: 0.334 - ETA: 3:50 - loss: 2.8120 - acc: 0.335 - ETA: 3:44 - loss: 2.7987 - acc: 0.338 - ETA: 3:39 - loss: 2.7900 - acc: 0.340 - ETA: 3:34 - loss: 2.7827 - acc: 0.342 - ETA: 3:29 - loss: 2.7685 - acc: 0.344 - ETA: 3:24 - loss: 2.7568 - acc: 0.347 - ETA: 3:19 - loss: 2.7445 - acc: 0.349 - ETA: 3:14 - loss: 2.7306 - acc: 0.353 - ETA: 3:08 - loss: 2.7231 - acc: 0.354 - ETA: 3:03 - loss: 2.7095 - acc: 0.358 - ETA: 2:58 - loss: 2.6955 - acc: 0.361 - ETA: 2:53 - loss: 2.6812 - acc: 0.365 - ETA: 2:48 - loss: 2.6713 - acc: 0.367 - ETA: 2:42 - loss: 2.6620 - acc: 0.368 - ETA: 2:37 - loss: 2.6523 - acc: 0.370 - ETA: 2:32 - loss: 2.6449 - acc: 0.372 - ETA: 2:27 - loss: 2.6379 - acc: 0.372 - ETA: 2:22 - loss: 2.6300 - acc: 0.374 - ETA: 2:16 - loss: 2.6212 - acc: 0.376 - ETA: 2:11 - loss: 2.6138 - acc: 0.378 - ETA: 2:06 - loss: 2.6049 - acc: 0.379 - ETA: 2:01 - loss: 2.5966 - acc: 0.382 - ETA: 1:56 - loss: 2.5838 - acc: 0.385 - ETA: 1:50 - loss: 2.5721 - acc: 0.388 - ETA: 1:45 - loss: 2.5598 - acc: 0.391 - ETA: 1:40 - loss: 2.5514 - acc: 0.393 - ETA: 1:35 - loss: 2.5426 - acc: 0.395 - ETA: 1:30 - loss: 2.5344 - acc: 0.397 - ETA: 1:25 - loss: 2.5261 - acc: 0.398 - ETA: 1:19 - loss: 2.5182 - acc: 0.400 - ETA: 1:14 - loss: 2.5081 - acc: 0.402 - ETA: 1:09 - loss: 2.4979 - acc: 0.405 - ETA: 1:04 - loss: 2.4883 - acc: 0.407 - ETA: 59s - loss: 2.4793 - acc: 0.409 - ETA: 54s - loss: 2.4699 - acc: 0.41 - ETA: 48s - loss: 2.4596 - acc: 0.41 - ETA: 43s - loss: 2.4492 - acc: 0.41 - ETA: 38s - loss: 2.4391 - acc: 0.41 - ETA: 33s - loss: 2.4314 - acc: 0.42 - ETA: 28s - loss: 2.4215 - acc: 0.42 - ETA: 23s - loss: 2.4117 - acc: 0.42 - ETA: 17s - loss: 2.4042 - acc: 0.42 - ETA: 12s - loss: 2.3976 - acc: 0.42 - ETA: 7s - loss: 2.3889 - acc: 0.4300 - ETA: 2s - loss: 2.3799 - acc: 0.432 - 1023s 196ms/step - loss: 2.3766 - acc: 0.4330 - val_loss: 1.0272 - val_acc: 0.7374\n",
      "Epoch 2/3\n",
      "2304/5231 [============>.................] - ETA: 13:20 - loss: 0.7496 - acc: 0.84 - ETA: 13:18 - loss: 1.0342 - acc: 0.75 - ETA: 13:13 - loss: 1.0157 - acc: 0.73 - ETA: 13:09 - loss: 0.8994 - acc: 0.75 - ETA: 13:02 - loss: 0.8901 - acc: 0.73 - ETA: 12:57 - loss: 0.8505 - acc: 0.74 - ETA: 12:54 - loss: 0.8481 - acc: 0.75 - ETA: 12:51 - loss: 0.8657 - acc: 0.74 - ETA: 12:45 - loss: 0.8272 - acc: 0.75 - ETA: 12:40 - loss: 0.8455 - acc: 0.75 - ETA: 12:36 - loss: 0.8182 - acc: 0.76 - ETA: 13:02 - loss: 0.8292 - acc: 0.76 - ETA: 12:59 - loss: 0.8019 - acc: 0.76 - ETA: 12:56 - loss: 0.7833 - acc: 0.77 - ETA: 12:51 - loss: 0.7899 - acc: 0.77 - ETA: 12:48 - loss: 0.7975 - acc: 0.77 - ETA: 12:42 - loss: 0.8119 - acc: 0.77 - ETA: 12:48 - loss: 0.8137 - acc: 0.77 - ETA: 12:50 - loss: 0.8046 - acc: 0.77 - ETA: 12:46 - loss: 0.7737 - acc: 0.78 - ETA: 12:41 - loss: 0.7780 - acc: 0.78 - ETA: 12:33 - loss: 0.7943 - acc: 0.77 - ETA: 12:27 - loss: 0.7925 - acc: 0.77 - ETA: 12:21 - loss: 0.7875 - acc: 0.77 - ETA: 12:13 - loss: 0.7793 - acc: 0.77 - ETA: 12:08 - loss: 0.7704 - acc: 0.77 - ETA: 12:03 - loss: 0.7628 - acc: 0.78 - ETA: 11:57 - loss: 0.7611 - acc: 0.78 - ETA: 11:52 - loss: 0.7601 - acc: 0.78 - ETA: 11:46 - loss: 0.7511 - acc: 0.78 - ETA: 11:40 - loss: 0.7425 - acc: 0.78 - ETA: 11:35 - loss: 0.7360 - acc: 0.79 - ETA: 11:29 - loss: 0.7370 - acc: 0.78 - ETA: 11:22 - loss: 0.7371 - acc: 0.79 - ETA: 11:17 - loss: 0.7435 - acc: 0.78 - ETA: 11:13 - loss: 0.7359 - acc: 0.78 - ETA: 11:07 - loss: 0.7342 - acc: 0.78 - ETA: 11:01 - loss: 0.7310 - acc: 0.78 - ETA: 10:55 - loss: 0.7217 - acc: 0.79 - ETA: 10:49 - loss: 0.7230 - acc: 0.79 - ETA: 10:44 - loss: 0.7231 - acc: 0.79 - ETA: 10:38 - loss: 0.7251 - acc: 0.79 - ETA: 10:32 - loss: 0.7221 - acc: 0.79 - ETA: 10:27 - loss: 0.7195 - acc: 0.79 - ETA: 10:21 - loss: 0.7296 - acc: 0.79 - ETA: 10:15 - loss: 0.7259 - acc: 0.79 - ETA: 10:10 - loss: 0.7308 - acc: 0.79 - ETA: 10:04 - loss: 0.7298 - acc: 0.79 - ETA: 9:58 - loss: 0.7261 - acc: 0.7953 - ETA: 9:53 - loss: 0.7296 - acc: 0.794 - ETA: 9:48 - loss: 0.7289 - acc: 0.795 - ETA: 9:43 - loss: 0.7274 - acc: 0.795 - ETA: 9:38 - loss: 0.7199 - acc: 0.796 - ETA: 9:32 - loss: 0.7214 - acc: 0.795 - ETA: 9:27 - loss: 0.7268 - acc: 0.794 - ETA: 9:22 - loss: 0.7290 - acc: 0.794 - ETA: 9:17 - loss: 0.7320 - acc: 0.794 - ETA: 9:12 - loss: 0.7284 - acc: 0.795 - ETA: 9:08 - loss: 0.7284 - acc: 0.796 - ETA: 9:03 - loss: 0.7239 - acc: 0.797 - ETA: 8:58 - loss: 0.7212 - acc: 0.797 - ETA: 8:55 - loss: 0.7216 - acc: 0.796 - ETA: 8:49 - loss: 0.7202 - acc: 0.797 - ETA: 8:44 - loss: 0.7171 - acc: 0.798 - ETA: 8:38 - loss: 0.7123 - acc: 0.799 - ETA: 8:32 - loss: 0.7092 - acc: 0.800 - ETA: 8:27 - loss: 0.7146 - acc: 0.798 - ETA: 8:21 - loss: 0.7137 - acc: 0.797 - ETA: 8:16 - loss: 0.7106 - acc: 0.798 - ETA: 8:11 - loss: 0.7047 - acc: 0.800 - ETA: 8:06 - loss: 0.7013 - acc: 0.800 - ETA: 8:00 - loss: 0.7007 - acc: 0.8003"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  \n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) \n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare('C:\\final model\\classification test.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES[np.argmax(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('road_side_detecttion_model','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "j = 0\n",
    "counter = 0\n",
    "for i in range(0,59):\n",
    "    src_dir = \"C:/final model/classification train\"+str(i)+\"/\"\n",
    "    dst_dir = src_dir\n",
    "    j = 0\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter+=1\n",
    "        for jpgfile in glob.iglob(os.path.join(src_dir+'track'+str(j), \"*.png\")):\n",
    "            shutil.copy(jpgfile, dst_dir)\n",
    "        j+=1\n",
    "        if counter == 50:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
